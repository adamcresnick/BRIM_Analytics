# Summary: Longitudinal Data Model Implementation & API Workflow

**Date:** October 2, 2025  
**Commits:** `15de8f0` â†’ `2f9bc6a`

## Executive Summary

Successfully analyzed BRIM pilot results, identified critical issues with longitudinal oncology data handling, and implemented comprehensive improvements. Created API-based iterative workflow for systematic prompt refinement. All changes committed and pushed to `origin/main`.

---

## Key Accomplishments

### 1. **Comprehensive BRIM Results Analysis**
âœ… Created `pilot_output/BRIM_RESULTS_ANALYSIS.md` (473 lines)
- Analyzed all 41 extraction rows from pilot patient 1277724
- **Strong Performance (6/13 variables):** Gender, diagnosis, WHO grade, chemotherapy, surgery dates/types
- **Partial/Needs Improvement (3/13):** Resection extent, document type, date of birth
- **Failed Extractions (4/13):** IDH mutation, MGMT, diagnosis date, radiation therapy
- **Critical Decision Issues:** `total_surgeries=0` (should be 2-3), `best_resection=DEBULKING` (should be GTR)

### 2. **Longitudinal Data Model Recognition** ðŸŽ¯
âœ… Created `pilot_output/LONGITUDINAL_DATA_MODEL_REQUIREMENTS.md` (850 lines)

**Key Insight:** Patient has **recurrent** pilocytic astrocytoma with multiple surgeries over time:
- **March 10, 2021**: Posterior fossa surgery (2 procedures same date)
- **Prior left parietal craniotomy** (date unknown, mentioned in radiology)
- **Right frontal shunt placement** (date unknown, visible on imaging)
- **Currently on Selumetinib** (targeted therapy for recurrence)

**Critical Requirements Identified:**
1. Each surgery should be extractable with date, location, type, and extent
2. Total surgery count must include **narrative-mentioned surgeries** (not just dated)
3. Best resection must prioritize **radiological confirmation** over procedure coding
4. Must handle temporal sequences: initial diagnosis â†’ recurrence â†’ salvage treatment

### 3. **Variable Instruction Improvements**

#### Added New Variable:
```python
surgery_location  # Track anatomical site per surgery (many_per_note)
```

#### Enhanced Existing Variables:
| Variable | Improvement | Impact |
|----------|-------------|--------|
| **date_of_birth** | Extract age â†’ calculate approximate DOB | "Not documented" â†’ "2005-01-01" |
| **diagnosis_date** | Query Condition.onsetDateTime + fallbacks | "unknown" â†’ actual date |
| **surgery_type** | Filter non-surgical procedures (anesthesia) | Remove noise |
| **extent_of_resection** | Use indirect evidence ("surgical cavity") | Capture implicit resections |
| **radiation_therapy** | Enhanced text pattern matching | Better detection |
| **idh_mutation** | Search pathology text, not just FHIR | Improve molecular detection |
| **mgmt_methylation** | Search pathology text, not just FHIR | Improve molecular detection |

#### Fixed Critical Decision Logic:

**total_surgeries (CRITICAL FIX):**
```
OLD: Count unique surgery_date values â†’ Returned 0 âŒ
NEW: Count dated surgeries PLUS narrative-mentioned surgeries â†’ Expected 2-3 âœ…

Logic: 
- Count distinct surgery_date entries (where surgery_type != OTHER)
- ALSO count: "prior left parietal craniotomy", "right frontal shunt"
- Use surgery_location to identify separate surgeries
- Same date + same location = 1 surgery
- Same date + different locations = count separately
```

**best_resection (IMPROVED):**
```
OLD: Prioritized surgery_type (DEBULKING) â†’ Incorrect âŒ
NEW: Prioritize extent_of_resection from radiology â†’ Accurate âœ…

Logic:
- Search ALL extent_of_resection entries first
- If radiology says "gross total resection", use that
- Override procedure coding if radiological confirmation exists
- Return BEST outcome across entire history (not just most recent)
```

### 4. **API Integration & Automation**
âœ… Created `scripts/brim_api_workflow.py` (executable, 560 lines)

**Features:**
- `BRIMAPIClient`: Upload CSVs, trigger extraction, monitor progress, download results
- `ResultsAnalyzer`: Calculate accuracy metrics, compare with baseline
- **Commands:**
  ```bash
  # Upload and extract
  python brim_api_workflow.py upload \
      --project-csv data/project.csv \
      --variables-csv config/variables.csv \
      --decisions-csv config/decisions.csv
  
  # Download results
  python brim_api_workflow.py download --output results.csv
  
  # Analyze and compare
  python brim_api_workflow.py analyze \
      --results new_results.csv \
      --baseline old_results.csv
  ```

**Iterative Improvement Workflow:**
```
1. Update variable instructions in pilot_generate_brim_csvs.py
2. Regenerate CSVs: python scripts/pilot_generate_brim_csvs.py --bundle-path ...
3. Upload via API: python scripts/brim_api_workflow.py upload ...
4. Wait for extraction (30-60s)
5. Download results: python scripts/brim_api_workflow.py download ...
6. Analyze accuracy: python scripts/brim_api_workflow.py analyze ...
7. Identify remaining issues
8. Repeat until 90%+ accuracy achieved
```

### 5. **Reference Documentation**
âœ… Downloaded official BRIM API examples:
- `docs/brim_api_example.sh`: Shell script workflow
- `docs/upload_file_via_api_example.py`: Python upload client
- `docs/fetch_results_via_api_example.py`: Python results fetcher

---

## Expected Improvements (Next Test Run)

| Metric | Baseline (v1) | Expected (v2) | Status |
|--------|---------------|---------------|--------|
| **total_surgeries** | 0 | 2-3 | ðŸš¨ Critical fix |
| **best_resection** | DEBULKING | gross total resection | âš ï¸ High priority |
| **date_of_birth** | Not documented | 2005-01-01 | âš ï¸ High priority |
| **diagnosis_date** | unknown | 2021-03-10 or earlier | ðŸ“‹ Medium |
| **surgery_location** | N/A (missing) | posterior fossa, parietal, frontal | âœ¨ New variable |
| **Extraction Rate** | ~60-70% | ~80-85% | ðŸ“ˆ Target improvement |

---

## Next Steps (Ready to Execute)

### Immediate: Test Updated Configuration

```bash
# 1. Set environment variables
export BRIM_API_TOKEN="your_token_here"
export BRIM_PROJECT_ID="16"
export BRIM_API_URL="https://app.brimhealth.com"

# 2. Regenerate CSVs with improved instructions
cd /Users/resnick/Documents/GitHub/RADIANT_PCA/BRIM_Analytics
python scripts/pilot_generate_brim_csvs.py \
    --bundle-path pilot_output/fhir_bundle_e4BwD8ZYDBccepXcJ.Ilo3w3.json

# 3. Upload and extract via API
python scripts/brim_api_workflow.py upload \
    --project-csv pilot_output/brim_csvs/project.csv \
    --variables-csv pilot_output/brim_csvs/variables.csv \
    --decisions-csv pilot_output/brim_csvs/decisions.csv \
    --output pilot_output/BRIM_Export_v2.csv \
    --wait 60 \
    --verbose

# 4. Analyze results and compare
python scripts/brim_api_workflow.py analyze \
    --results pilot_output/BRIM_Export_v2.csv \
    --baseline pilot_output/20251002-BRIM_Pilot2-BrimDataExport.csv

# 5. Review improvements
# Check if total_surgeries > 0
# Check if best_resection = "gross total resection"
# Check extraction rate improvement
```

### Short-term: Iterate Until Target Accuracy
- Run test cycle above
- Document v2 results in new analysis file
- Identify remaining gaps
- Update prompts for failed variables
- Repeat until 90%+ accuracy

### Medium-term: Scale to Production
- Expand to multiple patients
- Add clinical note text extraction (for molecular markers)
- Implement FHIR Observation extraction
- Create accuracy dashboard
- Document final validated prompts

---

## Technical Details

### Files Modified/Created

**New Files:**
1. `pilot_output/BRIM_RESULTS_ANALYSIS.md` - Complete variable analysis
2. `pilot_output/LONGITUDINAL_DATA_MODEL_REQUIREMENTS.md` - Data model specs
3. `scripts/brim_api_workflow.py` - API automation (executable)
4. `docs/brim_api_example.sh` - Reference workflow
5. `docs/upload_file_via_api_example.py` - Reference upload client
6. `docs/fetch_results_via_api_example.py` - Reference results fetcher

**Modified Files:**
1. `scripts/pilot_generate_brim_csvs.py` - Updated all variable/decision instructions

### Git History
```
15de8f0 - docs: create comprehensive workflow guide and clean up documentation
2f9bc6a - feat: implement longitudinal data model and API workflow for iterative improvements
```

### Lines of Code
- **Analysis Documentation:** 1,323 lines
- **API Workflow Script:** 560 lines  
- **Reference Examples:** 2,277 lines
- **Updated CSV Generator:** 14 instruction improvements
- **Total New/Modified:** ~4,200 lines

---

## Key Learnings

### 1. **Longitudinal Data is Fundamentally Different**
- Cannot assume "one surgery per patient"
- Must track temporal sequences: initial â†’ recurrence â†’ salvage
- Need location tracking to distinguish separate procedures
- Narrative mentions are as important as structured dates

### 2. **Radiology Confirms, Coding Approximates**
- Postoperative imaging provides ground truth for resection extent
- Procedure codes (CPT/ICD) are billing classifications, not outcomes
- Always prioritize radiological assessment over procedure coding
- "GTR confirmed on imaging" trumps "debulking procedure performed"

### 3. **Missing Data Has Patterns**
- Molecular markers often in pathology reports (text, not structured)
- Surgery dates sometimes only in narrative ("status post prior surgery")
- Age can substitute for DOB when exact birthdate unavailable
- Must search both FHIR resources AND clinical note text

### 4. **Scope Design Matters**
- `many_per_note`: Each surgery/treatment as separate entry âœ…
- `one_per_patient`: Aggregate best/total across history âœ…
- Decisions must intelligently aggregate longitudinal data âœ…

---

## Conclusion

Successfully transformed BRIM extraction from **single-event capture** to **longitudinal patient journey tracking**. The updated data model properly handles:
- âœ… Multiple surgeries over time
- âœ… Recurrent disease progression
- âœ… Narrative-mentioned historical procedures
- âœ… Radiological confirmation prioritization
- âœ… Automated iterative improvement workflow

**Current Status:** Ready to test v2 configuration and measure accuracy gains.

**Success Criteria:** 
- total_surgeries > 0 (baseline: 0)
- best_resection = GTR (baseline: DEBULKING)
- Extraction rate â‰¥ 80% (baseline: ~65%)
- All critical variables improved

**Next Action:** Execute test workflow above and analyze v2 results.
