# V4.2 Two-Agent Workflow Enhancements
**Orchestrator-Extractor Architecture Improvements**

**Document Version:** 1.0
**Created:** 2025-11-03
**Author:** RADIANT PCA Engineering Team + External Review
**Status:** Planning Phase

---

## Executive Summary

This document outlines enhancements to the two-agent workflow (Claude Orchestrator + MedGemma Extractor) based on external expert review and internal analysis. The reviewer confirmed our architecture is **state-of-the-art** and provided three high-value improvement recommendations.

### External Review Assessment

> "The two-agent workflow, separating the Orchestrator (Claude) from the Extractor (MedGemma), is a state-of-the-art approach for this kind of complex, multi-source data abstraction task. It moves beyond naive, 'one-shot' prompting and implements a more robust, efficient, and accurate system. I would consider this a **best-practice implementation for clinical AI**."

### Enhancement Priorities

| Enhancement | Priority | Effort | Impact | V4.2 Timeline |
|------------|----------|--------|--------|---------------|
| #1: Extraction Validation | â­â­â­ CRITICAL | Medium | High reliability | Week 2-3 |
| #2: Document Batching | â­â­ HIGH | Medium | 30-50% efficiency gain | Week 4-5 |
| #3: Dynamic Prioritization | â­ MEDIUM | High | Better clinical focus | V5.0 (deferred) |

---

## Table of Contents

1. [Current Two-Agent Architecture](#current-two-agent-architecture)
2. [Enhancement #1: Extraction Validation](#enhancement-1-extraction-validation)
3. [Enhancement #2: Document Batching](#enhancement-2-document-batching)
4. [Enhancement #3: Dynamic Prioritization](#enhancement-3-dynamic-prioritization)
5. [Integration with V4.2 Roadmap](#integration-with-v42-roadmap)
6. [Implementation Plan](#implementation-plan)

---

## Current Two-Agent Architecture

### Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLAUDE ORCHESTRATOR                          â”‚
â”‚                                                                 â”‚
â”‚  Phase 0: WHO Classification (MedGemma)                        â”‚
â”‚  Phase 1: Load Structured Data (Athena)                       â”‚
â”‚  Phase 2: Build Initial Timeline                              â”‚
â”‚  Phase 3: Gap Analysis & Prioritization                       â”‚
â”‚  Phase 4: Targeted Document Extraction (MedGemma)             â”‚
â”‚  Phase 5: Timeline Enrichment                                 â”‚
â”‚  Phase 6: JSON Serialization                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ Focused prompts with specific questions
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEDGEMMA EXTRACTOR                           â”‚
â”‚                                                                 â”‚
â”‚  Input: Text chunk + Specific question                        â”‚
â”‚  Output: Structured JSON answer                               â”‚
â”‚  Examples:                                                     â”‚
â”‚    - "Extract extent of resection from operative note"        â”‚
â”‚    - "Extract total radiation dose in cGy"                    â”‚
â”‚    - "Extract molecular findings for WHO classification"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Strengths (Per External Review)

1. **Separation of Concerns**: Orchestrator handles workflow; Extractor handles text â†’ structured data
2. **Efficiency**: Only processes documents needed to fill identified gaps
3. **Accuracy**: Task decomposition maximizes LLM reliability (e.g., two-stage WHO classification)
4. **Clinical Nuance**: Priority-based gap filling (e.g., HIGHEST priority for extent_of_resection)

### Current Workflow Example

**Scenario**: Patient has surgery on 2023-06-15, but `extent_of_resection` is missing from structured data.

```python
# Phase 3: Orchestrator identifies gap
gap = {
    'gap_type': 'missing_eor',
    'priority': 'HIGHEST',
    'surgery_date': '2023-06-15',
    'procedure_id': 'Procedure/12345',
    'medgemma_target': 'operative_note'
}

# Phase 4: Orchestrator finds best document
binary_id = self._find_operative_note_binary('2023-06-15')  # Temporal match Â±3 days

# Phase 4: Orchestrator sends focused prompt to MedGemma
prompt = f"""
Extract the extent of resection from this operative note.

OUTPUT SCHEMA (JSON):
{{
  "extent_of_resection": "GTR" | "STR" | "Biopsy" | null,
  "confidence": "HIGH" | "MEDIUM" | "LOW"
}}

OPERATIVE NOTE:
{binary_content[:8000]}
"""

result = self.medgemma_client.query(prompt)
# {'extent_of_resection': 'GTR', 'confidence': 'HIGH'}
```

---

## Enhancement #1: Extraction Validation

### Problem Statement

**Reviewer Observation:**
> "The workflow relies on the orchestrator correctly identifying the right document. If it mistakenly sends a discharge summary to a prompt expecting an operative note, the extractor might fail or return incorrect data."

**Current Risk:**
- Orchestrator uses temporal matching (Â±3 days) to find operative notes
- May retrieve wrong document type (discharge summary, consultation note)
- Extractor receives mismatched text and either:
  - Returns `null` (silent failure)
  - Hallucinates plausible but incorrect data
  - Returns irrelevant information
- No validation before integrating extracted data into timeline

**Example Failure Scenario:**

```python
# Orchestrator wants operative note for 2023-06-15 surgery
binary_id = self._find_operative_note_binary('2023-06-15')
# Returns discharge summary from 2023-06-17 (within Â±3 days)

# Extractor receives discharge summary with prompt asking for extent_of_resection
result = self.medgemma_client.query(prompt_for_eor, binary_content)
# Returns: {'extent_of_resection': null, 'confidence': 'LOW'}
# OR WORSE: {'extent_of_resection': 'Patient was discharged to home', 'confidence': 'MEDIUM'}

# Orchestrator integrates bad data without validation âŒ
```

### Proposed Solution: Multi-Layer Validation

Implement validation at **three layers**:

1. **Document Type Validation** (Pre-extraction)
2. **Extraction Result Validation** (Post-extraction)
3. **Clinical Event Validation** (Integration time)

#### Layer 1: Document Type Validation (Pre-Extraction)

Add document type verification before sending to MedGemma:

```python
def _validate_document_type(self, binary_id: str, expected_type: str) -> bool:
    """
    Verify document matches expected type before extraction

    Args:
        binary_id: FHIR Binary resource ID
        expected_type: Expected document type ("Operative Record", "Radiation Summary", etc.)

    Returns:
        True if document type matches expectation
    """
    # Query v2_document_reference_enriched for document metadata
    query = f"""
        SELECT doc_type_text, document_confidence
        FROM fhir_prd_db.v2_document_reference_enriched
        WHERE binary_id = '{binary_id}'
    """

    result = self._execute_athena_query(query)
    if not result:
        logger.warning(f"âš ï¸ Could not verify document type for binary {binary_id}")
        return False

    doc_type = result[0]['doc_type_text']

    # Fuzzy match for document type (e.g., "Operative Record" matches "operative_note")
    type_matches = {
        'operative_note': ['Operative Record', 'Procedure Note', 'Operative Report'],
        'radiation_summary': ['Radiation Therapy Summary', 'Radiation Oncology Note'],
        'imaging_report': ['Diagnostic Imaging Report', 'Radiology Report'],
        'pathology_report': ['Pathology Report', 'Surgical Pathology']
    }

    if doc_type in type_matches.get(expected_type, []):
        logger.info(f"âœ… Document type validated: {doc_type} matches {expected_type}")
        return True
    else:
        logger.warning(f"âš ï¸ Document type mismatch: expected {expected_type}, got {doc_type}")
        return False
```

**Usage in Phase 4:**

```python
# BEFORE extraction
binary_id = self._find_operative_note_binary(surgery_date_str)
if not binary_id:
    logger.warning(f"âš ï¸ No operative note found for surgery {surgery_date_str}")
    continue

# NEW: Validate document type
if not self._validate_document_type(binary_id, 'operative_note'):
    logger.warning(f"âš ï¸ Document {binary_id} is not an operative note, skipping")
    # Try alternative document discovery
    binary_id = self._find_operative_note_binary_v2(procedure_id, encounter_id)
    if not binary_id or not self._validate_document_type(binary_id, 'operative_note'):
        continue

# Proceed with extraction
binary_content = self._fetch_binary_content(binary_id)
result = self.medgemma_client.query(prompt, binary_content)
```

#### Layer 2: Extraction Result Validation (Post-Extraction)

Add semantic validation of MedGemma output:

```python
def _validate_extraction_result(
    self,
    result: Dict[str, Any],
    gap_type: str,
    expected_schema: Dict[str, type]
) -> Tuple[bool, List[str]]:
    """
    Validate MedGemma extraction result for semantic correctness

    Args:
        result: Extracted data from MedGemma
        gap_type: Type of gap being filled (e.g., 'missing_eor')
        expected_schema: Expected output schema

    Returns:
        (is_valid, list_of_errors)
    """
    errors = []

    # 1. Schema validation
    for field, field_type in expected_schema.items():
        if field not in result:
            errors.append(f"Missing required field: {field}")
        elif result[field] is not None and not isinstance(result[field], field_type):
            errors.append(f"Field {field} has wrong type: expected {field_type}, got {type(result[field])}")

    # 2. Semantic validation (gap-type specific)
    if gap_type == 'missing_eor':
        eor_value = result.get('extent_of_resection')
        valid_eor_values = ['GTR', 'NTR', 'STR', 'Biopsy', None]

        if eor_value not in valid_eor_values:
            errors.append(f"Invalid extent_of_resection value: {eor_value}")

        # Check for nonsensical text (likely document mismatch)
        if eor_value and len(str(eor_value)) > 50:
            errors.append(f"Extent of resection value too long (likely extraction error): {eor_value[:50]}...")

    elif gap_type == 'missing_radiation_dose':
        dose = result.get('total_dose_cgy')

        if dose is not None:
            # Radiation dose sanity checks
            if not isinstance(dose, (int, float)):
                errors.append(f"Invalid dose type: {type(dose)}")
            elif dose < 0 or dose > 10000:  # Typical range: 1800-6000 cGy
                errors.append(f"Dose out of reasonable range: {dose} cGy")

    elif gap_type == 'missing_tumor_location':
        location = result.get('tumor_location')

        if location:
            # Check if location is plausible (not generic text)
            generic_phrases = [
                'patient was', 'discharged', 'follow-up', 'appointment',
                'medication', 'vital signs', 'assessment', 'plan'
            ]
            if any(phrase in location.lower() for phrase in generic_phrases):
                errors.append(f"Tumor location appears to be generic text (document mismatch): {location[:100]}")

    # 3. Confidence check
    confidence = result.get('confidence', 'MEDIUM')
    if confidence == 'LOW':
        errors.append("Extraction confidence is LOW - may indicate document mismatch or unclear text")

    is_valid = len(errors) == 0
    return is_valid, errors
```

**Usage in Phase 4:**

```python
# After MedGemma extraction
result = self.medgemma_client.query(prompt, binary_content)

# NEW: Validate extraction result
expected_schema = {'extent_of_resection': str, 'confidence': str}
is_valid, errors = self._validate_extraction_result(result, gap['gap_type'], expected_schema)

if not is_valid:
    logger.warning(f"âš ï¸ Extraction validation failed for {gap['gap_type']}: {errors}")
    # Log failed extraction for review
    self._log_failed_extraction(gap, binary_id, result, errors)
    # Try alternative document
    continue

# Proceed with integration
logger.info(f"âœ… Extraction validated: {result}")
```

#### Layer 3: Clinical Event Validation (Integration Time)

Use the new **V4.2 ClinicalEvent dataclass validation** when integrating extracted data:

```python
from lib.clinical_event import create_surgery_event, TumorMeasurement

# After extraction and validation, create clinical event
clinical_features = {}
if result.get('extent_of_resection'):
    clinical_features['extent_of_resection'] = result['extent_of_resection']

if result.get('tumor_location'):
    # Use V4.1 TumorLocationExtractor for normalization
    location_feature = self.tumor_location_extractor.extract_from_text(result['tumor_location'])
    if location_feature:
        clinical_features['tumor_location'] = location_feature.to_dict()

# Create event using V4.2 dataclass
event = create_surgery_event(
    event_date=surgery_date_str,
    surgery_type=surgery_type,
    clinical_features=clinical_features,
    v2_annotation=v2_annotation
)

# NEW: Validate event before adding to timeline
validation_errors = event.validate()
if validation_errors:
    logger.error(f"âŒ Clinical event validation failed: {validation_errors}")
    # Don't add invalid event to timeline
    continue

logger.info(f"âœ… Clinical event validated and added to timeline")
events.append(event.to_dict())
```

### Expected Impact

| Metric | Current | After Enhancement #1 |
|--------|---------|---------------------|
| Document mismatch detection | 0% (silent failures) | 90%+ (pre-extraction validation) |
| Invalid extraction detection | ~20% (schema errors at JSON serialization) | 95%+ (multi-layer validation) |
| Failed extraction rate | Unknown | Tracked and logged for review |
| Data quality confidence | Medium | High |

### Implementation Checklist

- [ ] Create `_validate_document_type()` method in Phase 4
- [ ] Create `_validate_extraction_result()` method with gap-type specific checks
- [ ] Create `_log_failed_extraction()` method to track failures
- [ ] Add extraction validation counters to telemetry
- [ ] Integrate ClinicalEvent.validate() at event creation time
- [ ] Create failed extractions review dashboard
- [ ] Add unit tests for all validation methods

---

## Enhancement #2: Document Batching

### Problem Statement

**Reviewer Observation:**
> "If multiple gaps (e.g., 'missing_eor' and 'tumor_location') both require processing the same operative note, the current workflow might fetch and send the document to the LLM twice with different prompts."

**Current Inefficiency:**

```python
# Gap 1: missing_eor for surgery on 2023-06-15
binary_id_1 = self._find_operative_note_binary('2023-06-15')  # Athena query + fetch
result_1 = self.medgemma_client.query(eor_prompt, binary_content_1)  # MedGemma call

# Gap 2: missing_tumor_location for same surgery
binary_id_2 = self._find_operative_note_binary('2023-06-15')  # DUPLICATE Athena query + fetch
result_2 = self.medgemma_client.query(location_prompt, binary_content_2)  # DUPLICATE MedGemma call
```

**Cost:**
- 2x document fetches from S3
- 2x MedGemma API calls
- 2x token processing costs
- ~2x total Phase 4 execution time

### Proposed Solution: Multi-Gap Batch Extraction

**Key Insight:** Our **V2 cross-resource annotation** already provides the linkage we need to batch gaps by document!

```python
# V2 annotation from surgery event
v2_annotation = {
    'encounter_id': 'Encounter/67890',
    'procedure_id': 'Procedure/12345',
    'performer_org_id': 'Organization/CHOP'
}

# Use encounter_id to find ALL documents for this encounter
# Then process ALL gaps related to that encounter in ONE batch
```

#### Step 1: Group Gaps by Target Document

```python
def _group_gaps_by_document(self, gaps: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """
    Group gaps by their target document for batch processing

    Args:
        gaps: List of identified gaps from Phase 3

    Returns:
        Dictionary mapping document_key -> list of gaps
    """
    grouped = {}

    for gap in gaps:
        # Determine document key based on gap target
        if gap['medgemma_target'] == 'operative_note':
            # Use procedure_id + encounter_id as key (from V2 annotation)
            procedure_id = gap.get('procedure_id')
            encounter_id = gap.get('encounter_id')
            doc_key = f"operative_note:{encounter_id or procedure_id}"

        elif gap['medgemma_target'] == 'radiation_summary':
            # Use treatment_id as key
            treatment_id = gap.get('treatment_id')
            doc_key = f"radiation_summary:{treatment_id}"

        elif gap['medgemma_target'] == 'imaging_report':
            # Use diagnostic_report_id as key
            diagnostic_report_id = gap.get('diagnostic_report_id')
            doc_key = f"imaging_report:{diagnostic_report_id}"

        else:
            # Unknown target - process individually
            doc_key = f"individual:{gap['gap_type']}"

        if doc_key not in grouped:
            grouped[doc_key] = []
        grouped[doc_key].append(gap)

    return grouped
```

**Example Output:**

```python
{
    'operative_note:Encounter/67890': [
        {'gap_type': 'missing_eor', 'priority': 'HIGHEST', ...},
        {'gap_type': 'missing_tumor_location', 'priority': 'HIGH', ...},
        {'gap_type': 'missing_laterality', 'priority': 'MEDIUM', ...}
    ],
    'radiation_summary:Procedure/22222': [
        {'gap_type': 'missing_radiation_dose', 'priority': 'HIGH', ...}
    ]
}
```

#### Step 2: Create Multi-Gap Prompts

```python
def _create_batch_extraction_prompt(
    self,
    gaps: List[Dict[str, Any]],
    document_type: str
) -> str:
    """
    Create a single prompt that extracts multiple features from one document

    Args:
        gaps: List of gaps to fill from this document
        document_type: Type of document being processed

    Returns:
        Multi-gap extraction prompt
    """
    if document_type == 'operative_note':
        # Build comprehensive operative note extraction
        prompt = """
You are a medical AI extracting surgical information from an operative note.

Extract the following information (return null if not found):

OUTPUT SCHEMA (JSON):
{
  "extent_of_resection": "GTR" | "NTR" | "STR" | "Biopsy" | null,
  "tumor_location": "specific anatomical location" | null,
  "laterality": "Left" | "Right" | "Bilateral" | "Midline" | null,
  "surgical_approach": "description of surgical approach" | null,
  "complications": "any complications mentioned" | null,
  "estimated_blood_loss_ml": <number> | null,
  "procedure_duration_minutes": <number> | null,
  "confidence": {
    "extent_of_resection": "HIGH" | "MEDIUM" | "LOW",
    "tumor_location": "HIGH" | "MEDIUM" | "LOW",
    "laterality": "HIGH" | "MEDIUM" | "LOW"
  }
}

OPERATIVE NOTE:
{binary_content}
"""

    elif document_type == 'radiation_summary':
        prompt = """
You are a medical AI extracting radiation therapy information.

Extract the following information (return null if not found):

OUTPUT SCHEMA (JSON):
{
  "total_dose_cgy": <number in centiGray> | null,
  "fractions": <number of fractions> | null,
  "target_volume": "description of treatment volume" | null,
  "technique": "IMRT" | "3D-CRT" | "Protons" | "Other" | null,
  "start_date": "YYYY-MM-DD" | null,
  "end_date": "YYYY-MM-DD" | null,
  "confidence": {
    "total_dose_cgy": "HIGH" | "MEDIUM" | "LOW",
    "fractions": "HIGH" | "MEDIUM" | "LOW"
  }
}

RADIATION SUMMARY:
{binary_content}
"""

    elif document_type == 'imaging_report':
        # V4.2: Include tumor measurements extraction
        prompt = """
You are a medical AI extracting imaging findings.

Extract the following information (return null if not found):

OUTPUT SCHEMA (JSON):
{
  "tumor_location": "anatomical location" | null,
  "tumor_measurements": [
    {
      "lesion_id": "target_1",
      "longest_diameter_mm": <number>,
      "perpendicular_diameter_mm": <number>,
      "location": "specific location"
    }
  ] | null,
  "enhancement_pattern": "description" | null,
  "mass_effect": true | false | null,
  "treatment_response_qualitative": "improved" | "stable" | "worse" | "new lesion" | null,
  "confidence": {
    "tumor_location": "HIGH" | "MEDIUM" | "LOW",
    "tumor_measurements": "HIGH" | "MEDIUM" | "LOW"
  }
}

IMAGING REPORT:
{binary_content}
"""

    return prompt
```

#### Step 3: Batch Extraction Execution

```python
def _execute_phase4_batch_extraction(self):
    """
    Phase 4: Batch extraction - process multiple gaps per document
    """
    logger.info("=== Phase 4: Batch Document Extraction ===")

    # Step 1: Group gaps by target document
    grouped_gaps = self._group_gaps_by_document(self.gaps)

    logger.info(f"ðŸ“¦ Grouped {len(self.gaps)} gaps into {len(grouped_gaps)} document batches")

    # Step 2: Process each document batch
    extraction_results = {}

    for doc_key, gaps in grouped_gaps.items():
        logger.info(f"ðŸ“„ Processing document batch: {doc_key} ({len(gaps)} gaps)")

        # Parse document type from key
        document_type = doc_key.split(':')[0]

        # Step 3: Find document using V2 encounter linkage (preferred) or temporal matching (fallback)
        binary_id = self._find_document_for_batch(gaps[0], document_type)
        if not binary_id:
            logger.warning(f"âš ï¸ Could not find document for {doc_key}")
            continue

        # Step 4: Validate document type (Enhancement #1)
        if not self._validate_document_type(binary_id, document_type):
            logger.warning(f"âš ï¸ Document type validation failed for {binary_id}")
            continue

        # Step 5: Fetch document content ONCE
        binary_content = self._fetch_binary_content(binary_id)
        if not binary_content:
            continue

        # Step 6: Create batch extraction prompt
        prompt = self._create_batch_extraction_prompt(gaps, document_type)

        # Step 7: Execute SINGLE MedGemma call for ALL gaps
        logger.info(f"ðŸ¤– MedGemma batch extraction for {len(gaps)} features...")
        result = self.medgemma_client.query(prompt, binary_content)

        # Step 8: Validate batch result (Enhancement #1)
        is_valid, errors = self._validate_batch_extraction_result(result, gaps, document_type)
        if not is_valid:
            logger.warning(f"âš ï¸ Batch extraction validation failed: {errors}")
            continue

        # Step 9: Store results mapped to each gap
        extraction_results[doc_key] = {
            'binary_id': binary_id,
            'result': result,
            'gaps': gaps
        }

        logger.info(f"âœ… Batch extraction complete for {doc_key}")

    # Step 10: Integrate extraction results into timeline
    self._integrate_batch_extractions(extraction_results)

    logger.info(f"âœ… Phase 4 batch extraction complete: {len(extraction_results)} documents processed")
```

#### Step 4: Find Documents Using V2 Linkage

```python
def _find_document_for_batch(self, representative_gap: Dict[str, Any], document_type: str) -> Optional[str]:
    """
    Find document using V2 encounter linkage (preferred) or temporal matching (fallback)

    Args:
        representative_gap: Representative gap from batch (all gaps share same document)
        document_type: Type of document to find

    Returns:
        Binary ID of found document, or None
    """
    if document_type == 'operative_note':
        encounter_id = representative_gap.get('encounter_id')
        procedure_id = representative_gap.get('procedure_id')
        surgery_date = representative_gap.get('surgery_date')

        # V2 TIER 1: Encounter-based lookup (95%+ success rate)
        if encounter_id:
            query = f"""
                SELECT binary_id, doc_type_text
                FROM fhir_prd_db.v2_document_reference_enriched
                WHERE encounter_id = '{encounter_id}'
                  AND doc_type_text IN ('Operative Record', 'Procedure Note', 'Operative Report')
                ORDER BY document_confidence DESC
                LIMIT 1
            """
            result = self._execute_athena_query(query)
            if result:
                logger.info(f"âœ… V2 Tier 1: Found operative note via encounter linkage")
                return result[0]['binary_id']

        # FALLBACK: Temporal matching (70% success rate)
        if surgery_date:
            logger.warning(f"âš ï¸ V2 Tier 1 failed, falling back to temporal matching")
            return self._find_operative_note_binary(surgery_date)

    elif document_type == 'radiation_summary':
        # Similar logic for radiation documents
        pass

    elif document_type == 'imaging_report':
        # V2 TIER 1: Use diagnostic_report_id -> binary_content_id direct linkage
        diagnostic_report_id = representative_gap.get('diagnostic_report_id')

        if diagnostic_report_id:
            # Check if v_imaging already has binary_content_id (V2 enhancement)
            imaging_event = next(
                (e for e in self.timeline_events if e.get('diagnostic_report_id') == diagnostic_report_id),
                None
            )
            if imaging_event and imaging_event.get('binary_content_id'):
                logger.info(f"âœ… V2 Tier 1: Found imaging report via binary_content_id")
                return imaging_event['binary_content_id']

    return None
```

### Expected Impact

| Metric | Current (Sequential) | After Enhancement #2 (Batching) |
|--------|---------------------|--------------------------------|
| Documents fetched per surgery | 3-5 (eor, location, laterality) | 1 (batch) |
| MedGemma API calls per surgery | 3-5 | 1 |
| Phase 4 execution time | 100% baseline | 30-50% reduction |
| S3 fetch operations | 3-5 per surgery | 1 per surgery |
| Token processing costs | 100% baseline | 40-60% reduction |
| Document discovery accuracy | 70% (temporal) | 95% (V2 encounter linkage) |

### Implementation Checklist

- [ ] Create `_group_gaps_by_document()` method
- [ ] Create `_create_batch_extraction_prompt()` for each document type
- [ ] Create `_find_document_for_batch()` with V2 encounter linkage
- [ ] Create `_validate_batch_extraction_result()` method
- [ ] Create `_integrate_batch_extractions()` method
- [ ] Refactor Phase 4 to use batch extraction workflow
- [ ] Add batch extraction telemetry (gaps per batch, time savings)
- [ ] Test on 10-patient cohort and measure efficiency gains
- [ ] Create fallback for individual extraction if batching fails

---

## Enhancement #3: Dynamic Prioritization

### Problem Statement

**Reviewer Observation:**
> "The priority of a gap is currently static (e.g., missing_eor is always HIGHEST). In a future version, consider making the prioritization dynamic. For example, an imaging study showing potential progression (PD) should dramatically increase the priority of all subsequent extraction tasks related to that timepoint."

**Current Static Prioritization:**

```python
# Phase 3: Gap analysis
PRIORITY_MAP = {
    'missing_eor': 'HIGHEST',
    'missing_radiation_dose': 'HIGH',
    'missing_tumor_location': 'MEDIUM',
    'missing_laterality': 'LOW'
}
```

**Problem:** This doesn't account for clinical context:
- Imaging showing progression is more urgent than stable disease
- New diagnosis changes importance of molecular testing
- Treatment changes trigger need for response assessment

### Proposed Solution: Context-Aware Dynamic Prioritization

âš ï¸ **IMPORTANT:** This is a **V5.0 enhancement** (deferred from V4.2) because it requires:
1. V4.2 tumor measurement extraction to be operational
2. V4.2 treatment response assessment to be operational
3. Clinical validation of prioritization logic
4. Extensive testing to avoid incorrect urgency assignments

#### V5.0 Dynamic Prioritization Logic

```python
def _calculate_dynamic_priority(
    self,
    gap: Dict[str, Any],
    timeline_context: List[Dict[str, Any]]
) -> str:
    """
    Calculate dynamic priority based on clinical context

    Args:
        gap: Identified gap
        timeline_context: Full timeline events for context

    Returns:
        Priority level: URGENT | HIGHEST | HIGH | MEDIUM | LOW
    """
    base_priority = self._get_base_priority(gap['gap_type'])

    # Context modifiers
    priority_modifiers = []

    # 1. PROGRESSION DETECTED: Elevate all related gaps
    if self._recent_progression_detected(timeline_context, gap['event_date']):
        priority_modifiers.append(('progression_detected', +2))
        logger.info(f"ðŸ”º Elevated priority for {gap['gap_type']} due to recent progression")

    # 2. NEW DIAGNOSIS: Elevate molecular testing gaps
    if gap['gap_type'] == 'missing_molecular_markers':
        if self._is_near_diagnosis_date(timeline_context, gap['event_date']):
            priority_modifiers.append(('new_diagnosis', +1))

    # 3. TREATMENT CHANGE: Elevate pre/post-treatment imaging gaps
    if self._treatment_change_detected(timeline_context, gap['event_date']):
        if gap['medgemma_target'] == 'imaging_report':
            priority_modifiers.append(('treatment_change', +1))

    # 4. CLINICAL TRIAL ENROLLMENT: Elevate all gaps (completeness critical)
    if self._clinical_trial_enrollment(timeline_context):
        priority_modifiers.append(('clinical_trial', +1))

    # Calculate final priority
    priority_score = self._priority_to_score(base_priority)
    for modifier_name, modifier_value in priority_modifiers:
        priority_score += modifier_value

    final_priority = self._score_to_priority(priority_score)

    if final_priority != base_priority:
        logger.info(f"ðŸ”„ Dynamic prioritization: {gap['gap_type']} {base_priority} â†’ {final_priority}")

    return final_priority


def _recent_progression_detected(self, timeline_events: List[Dict], reference_date: str) -> bool:
    """
    Check if recent imaging shows disease progression

    Requires V4.2 treatment_response extraction to be operational
    """
    from datetime import datetime, timedelta
    ref_date = datetime.fromisoformat(reference_date)

    # Look for imaging events in past 90 days
    recent_imaging = [
        e for e in timeline_events
        if e['event_type'] == 'imaging'
        and (ref_date - datetime.fromisoformat(e['event_date'])).days <= 90
    ]

    for imaging in recent_imaging:
        response = imaging.get('treatment_response', {})
        if response.get('response_category') in ['PD', 'worse']:
            return True

    return False


def _priority_to_score(self, priority: str) -> int:
    """Convert priority string to numeric score"""
    return {
        'URGENT': 5,
        'HIGHEST': 4,
        'HIGH': 3,
        'MEDIUM': 2,
        'LOW': 1
    }.get(priority, 2)


def _score_to_priority(self, score: int) -> str:
    """Convert numeric score to priority string"""
    if score >= 5:
        return 'URGENT'
    elif score >= 4:
        return 'HIGHEST'
    elif score >= 3:
        return 'HIGH'
    elif score >= 2:
        return 'MEDIUM'
    else:
        return 'LOW'
```

### Clinical Validation Requirements

Before implementing dynamic prioritization, we need:

1. **Clinical Expert Review**: Neuro-oncologists must validate prioritization logic
2. **Retrospective Testing**: Test on 100+ patient cohorts with known outcomes
3. **Audit Trail**: Log all priority adjustments with rationale
4. **Override Mechanism**: Allow manual priority adjustment if needed
5. **Metrics**: Track extraction quality vs. priority to validate logic

### Expected Impact (V5.0)

| Metric | Static Priority | Dynamic Priority (V5.0) |
|--------|----------------|------------------------|
| High-value gap extraction rate | 85% | 95%+ (context-aware) |
| Critical data completeness | 80% | 95%+ (progression-aware) |
| Wasted extraction effort | 15% | 5% (deprioritize stable disease) |
| Clinical relevance score | Baseline | +30-40% (focus on urgent cases) |

### Implementation Checklist (V5.0 - DEFERRED)

- [ ] âœ‹ **BLOCKER:** Complete V4.2 tumor measurement extraction
- [ ] âœ‹ **BLOCKER:** Complete V4.2 treatment response assessment
- [ ] Design dynamic prioritization algorithm with clinical input
- [ ] Create `_calculate_dynamic_priority()` method
- [ ] Create context detection methods (_recent_progression_detected, etc.)
- [ ] Add priority adjustment audit logging
- [ ] Retrospective validation on 100-patient cohort
- [ ] Clinical expert review and sign-off
- [ ] A/B testing: static vs. dynamic prioritization
- [ ] Production deployment with monitoring

---

## Integration with V4.2 Roadmap

These enhancements integrate seamlessly with the **V4.2_V5.0_UPGRADE_ROADMAP.md**:

### V4.2 Timeline Integration

| Week | V4.2 Core Enhancement | Two-Agent Enhancement | Integration Point |
|------|----------------------|----------------------|-------------------|
| 1-4 | ClinicalEvent dataclass | - | Foundation for Layer 3 validation |
| 2-3 | - | **Enhancement #1: Extraction Validation** | Use ClinicalEvent.validate() |
| 4-5 | - | **Enhancement #2: Document Batching** | Use V2 encounter linkage |
| 5 | V2 Document Discovery (Steps 3-4) | Enhancement #2 prerequisite | V2 encounter linkage enables batching |
| 6-7 | Tumor Measurement Extraction | - | Required for Enhancement #3 (V5.0) |
| 7 | Basic Treatment Response | - | Required for Enhancement #3 (V5.0) |

### Combined V4.2 Features

```python
# V4.2 COMPLETE WORKFLOW EXAMPLE

# Phase 3: Gap Analysis
gaps = self._identify_gaps()

# Enhancement #2: Batch gaps by document
grouped_gaps = self._group_gaps_by_document(gaps)

# Phase 4: Batch Extraction
for doc_key, batch_gaps in grouped_gaps.items():
    # Enhancement #1 Layer 1: Document type validation
    binary_id = self._find_document_for_batch(batch_gaps[0], document_type)
    if not self._validate_document_type(binary_id, expected_type):
        continue

    # Batch extraction
    binary_content = self._fetch_binary_content(binary_id)
    result = self.medgemma_client.query(batch_prompt, binary_content)

    # Enhancement #1 Layer 2: Extraction result validation
    is_valid, errors = self._validate_batch_extraction_result(result, batch_gaps)
    if not is_valid:
        self._log_failed_extraction(batch_gaps, binary_id, result, errors)
        continue

    # V4.2 Dataclass: Create clinical event
    event = create_imaging_event(
        event_date=event_date,
        imaging_modality=modality,
        tumor_measurements=[
            TumorMeasurement(**tm) for tm in result.get('tumor_measurements', [])
        ],
        treatment_response=TreatmentResponse(**result.get('treatment_response', {}))
    )

    # Enhancement #1 Layer 3: Clinical event validation
    validation_errors = event.validate()
    if validation_errors:
        logger.error(f"Event validation failed: {validation_errors}")
        continue

    # Integration
    events.append(event.to_dict())
```

---

## Implementation Plan

### V4.2 Immediate Priorities (Weeks 2-5)

#### Week 2-3: Enhancement #1 - Extraction Validation

**Goals:**
- Implement 3-layer validation
- Reduce failed extractions by 80%
- Improve data quality confidence to HIGH

**Tasks:**
1. Create `_validate_document_type()` method
2. Create `_validate_extraction_result()` with gap-type specific checks
3. Create `_log_failed_extraction()` tracking system
4. Integrate `ClinicalEvent.validate()` at event creation
5. Add validation telemetry counters
6. Test on 10-patient cohort
7. Review failed extraction logs and refine validation rules

**Success Metrics:**
- Document type mismatch detection: >90%
- Invalid extraction detection: >95%
- Failed extraction tracking: 100%
- Data quality confidence: HIGH

#### Week 4-5: Enhancement #2 - Document Batching

**Goals:**
- Reduce Phase 4 execution time by 30-50%
- Reduce MedGemma API calls by 60-70%
- Improve document discovery accuracy to 95%+

**Tasks:**
1. Create `_group_gaps_by_document()` method
2. Create batch extraction prompts for each document type
3. Create `_find_document_for_batch()` with V2 encounter linkage
4. Create `_validate_batch_extraction_result()` method
5. Create `_integrate_batch_extractions()` method
6. Refactor Phase 4 to use batch extraction
7. Add batch extraction telemetry
8. Performance benchmark on 10-patient cohort
9. Compare accuracy: batched vs. sequential extraction

**Success Metrics:**
- Documents fetched per patient: 70% reduction
- MedGemma API calls: 60%+ reduction
- Phase 4 execution time: 30-50% faster
- Document discovery accuracy: 95%+ (V2 encounter linkage)
- Extraction accuracy: Same or better vs. sequential

### V5.0 Deferred Priorities (12-16 weeks from now)

#### Enhancement #3: Dynamic Prioritization

**Prerequisites:**
- âœ… V4.2 tumor measurement extraction operational
- âœ… V4.2 treatment response assessment operational
- âœ… Clinical validation framework established

**Goals:**
- Context-aware gap prioritization
- Focus extraction effort on clinically urgent data
- Improve high-value data completeness to 95%+

**Tasks:**
1. Design dynamic prioritization algorithm with clinical input
2. Implement context detection methods
3. Create priority adjustment audit logging
4. Retrospective validation on 100-patient cohort
5. Clinical expert review and approval
6. A/B testing vs. static prioritization
7. Production deployment with monitoring

---

## Testing Strategy

### Unit Tests

```python
# tests/test_extraction_validation.py

def test_document_type_validation():
    """Test document type validation catches mismatches"""
    extractor = PatientTimelineExtractor(patient_id='test')

    # Mock v2_document_reference_enriched query
    with patch.object(extractor, '_execute_athena_query') as mock_query:
        mock_query.return_value = [{'doc_type_text': 'Discharge Summary'}]

        # Should reject discharge summary for operative note
        assert not extractor._validate_document_type('Binary/123', 'operative_note')

        mock_query.return_value = [{'doc_type_text': 'Operative Record'}]

        # Should accept operative record for operative note
        assert extractor._validate_document_type('Binary/123', 'operative_note')


def test_extraction_result_validation_eor():
    """Test extraction result validation for extent of resection"""
    extractor = PatientTimelineExtractor(patient_id='test')

    # Valid extraction
    result = {'extent_of_resection': 'GTR', 'confidence': 'HIGH'}
    is_valid, errors = extractor._validate_extraction_result(result, 'missing_eor', {...})
    assert is_valid
    assert len(errors) == 0

    # Invalid extraction (nonsensical text)
    result = {'extent_of_resection': 'Patient was discharged to home', 'confidence': 'MEDIUM'}
    is_valid, errors = extractor._validate_extraction_result(result, 'missing_eor', {...})
    assert not is_valid
    assert 'too long' in errors[0]


def test_gap_batching():
    """Test gaps are correctly grouped by document"""
    extractor = PatientTimelineExtractor(patient_id='test')

    gaps = [
        {'gap_type': 'missing_eor', 'encounter_id': 'Enc1', 'medgemma_target': 'operative_note'},
        {'gap_type': 'missing_tumor_location', 'encounter_id': 'Enc1', 'medgemma_target': 'operative_note'},
        {'gap_type': 'missing_radiation_dose', 'treatment_id': 'Tx1', 'medgemma_target': 'radiation_summary'}
    ]

    grouped = extractor._group_gaps_by_document(gaps)

    assert len(grouped) == 2  # Two unique documents
    assert len(grouped['operative_note:Enc1']) == 2  # Two gaps for same operative note
    assert len(grouped['radiation_summary:Tx1']) == 1  # One gap for radiation summary
```

### Integration Tests

```python
# tests/test_batch_extraction_integration.py

def test_batch_extraction_end_to_end():
    """Test full batch extraction workflow"""
    extractor = PatientTimelineExtractor(patient_id='eQSB0y3q.OmvN40Yhg9.eCBk5-9c-Qp-FT3pBWoSGuL83')

    # Run full workflow
    extractor.run()

    # Verify batch extraction was used
    assert extractor.telemetry['batch_extraction_used'] == True
    assert extractor.telemetry['avg_gaps_per_batch'] >= 2.0
    assert extractor.telemetry['phase4_execution_time'] < baseline_time * 0.7  # 30%+ faster

    # Verify data quality is maintained
    assert extractor.telemetry['extraction_accuracy'] >= 0.95
```

### Performance Benchmarks

```python
# scripts/benchmark_batch_extraction.py

def benchmark_batch_vs_sequential():
    """Compare batch extraction vs. sequential on 10-patient cohort"""
    test_patients = [...]  # 10 test patient IDs

    # Sequential extraction (baseline)
    sequential_times = []
    for patient_id in test_patients:
        extractor = PatientTimelineExtractor(patient_id, batch_mode=False)
        start = time.time()
        extractor.run()
        sequential_times.append(time.time() - start)

    # Batch extraction
    batch_times = []
    for patient_id in test_patients:
        extractor = PatientTimelineExtractor(patient_id, batch_mode=True)
        start = time.time()
        extractor.run()
        batch_times.append(time.time() - start)

    # Report
    print(f"Sequential avg: {np.mean(sequential_times):.1f}s")
    print(f"Batch avg: {np.mean(batch_times):.1f}s")
    print(f"Speedup: {np.mean(sequential_times) / np.mean(batch_times):.1f}x")
```

---

## Success Metrics

### V4.2 Target Metrics

| Metric | Baseline (V4.1+V2) | V4.2 Target | Measurement Method |
|--------|-------------------|------------|-------------------|
| **Extraction Validation** | | | |
| Document type mismatch detection | 0% (silent failures) | 90%+ | Validation logs |
| Invalid extraction detection | ~20% (at JSON serialization) | 95%+ | Validation logs |
| Failed extraction tracking | 0% | 100% | Audit database |
| Data quality confidence | MEDIUM | HIGH | Manual review |
| **Document Batching** | | | |
| Documents fetched per patient | 5-8 | 2-3 | Telemetry counter |
| MedGemma API calls per patient | 5-8 | 2-3 | Telemetry counter |
| Phase 4 execution time | 100% baseline | 50-70% | Timer |
| S3 fetch operations | 5-8 | 2-3 | CloudWatch |
| Document discovery accuracy | 70% (temporal) | 95%+ (V2 encounter) | Manual validation |
| Extraction accuracy (batched) | N/A | â‰¥95% (same as sequential) | Clinical review |

### V5.0 Target Metrics (Deferred)

| Metric | V4.2 Baseline | V5.0 Target |
|--------|--------------|------------|
| High-value gap extraction rate | 85% | 95%+ |
| Critical data completeness | 80% | 95%+ |
| Wasted extraction effort | 15% | <5% |
| Clinical relevance score | Baseline | +30-40% |

---

## Conclusion

The external reviewer confirmed our two-agent architecture is **state-of-the-art** and provided three high-value enhancement recommendations:

1. **âœ… Enhancement #1 (Extraction Validation)** - ACCEPT for V4.2 Week 2-3
   - Critical for data quality and reliability
   - Integrates perfectly with V4.2 ClinicalEvent dataclass validation
   - Expected: 90%+ mismatch detection, 95%+ invalid extraction detection

2. **âœ… Enhancement #2 (Document Batching)** - ACCEPT for V4.2 Week 4-5
   - Significant efficiency gains (30-50% faster Phase 4)
   - Leverages our V2 cross-resource annotation (encounter linkage)
   - Expected: 60%+ reduction in API calls, 95%+ document discovery accuracy

3. **â¸ï¸ Enhancement #3 (Dynamic Prioritization)** - DEFER to V5.0
   - Excellent concept but requires V4.2 features to be operational first
   - Needs clinical validation before production use
   - Expected: +30-40% clinical relevance when implemented

These enhancements will make our already-excellent two-agent workflow even more robust, efficient, and clinically relevant.

---

**Next Steps:**
1. Share this document with the implementation agent
2. Prioritize Enhancement #1 (Weeks 2-3) after ClinicalEvent dataclass is complete
3. Implement Enhancement #2 (Weeks 4-5) in parallel with V2 Document Discovery
4. Plan Enhancement #3 for V5.0 after clinical validation framework is established
