#!/usr/bin/env python3
"""
Final end-to-end extraction for patient e4BwD8ZYDBccepXcJ.Ilo3w3
This will generate complete results for review
"""

import json
import logging
from pathlib import Path
from datetime import datetime
from form_extractors.integrated_pipeline_extractor import IntegratedPipelineExtractor

# Configure logging to show progress
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Suppress verbose AWS logging
for logger_name in ['boto3', 'botocore', 's3transfer', 'urllib3', 'httpx']:
    logging.getLogger(logger_name).setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

print("\n" + "="*80)
print("FINAL END-TO-END EXTRACTION FOR PATIENT e4BwD8ZYDBccepXcJ.Ilo3w3")
print("="*80)

# Patient configuration
patient_id = 'e4BwD8ZYDBccepXcJ.Ilo3w3'
birth_date = '2005-05-13'

# Paths
staging_base = Path('/Users/resnick/Documents/GitHub/RADIANT_PCA/BRIM_Analytics/athena_extraction_validation/scripts/config_driven_versions/staging_files')
binary_files_path = Path('/Users/resnick/Documents/GitHub/RADIANT_PCA/BRIM_Analytics/athena_extraction_validation/staging_files/ALL_BINARY_FILES_METADATA_WITH_AVAILABILITY.csv')
data_dictionary_path = Path('/Users/resnick/Documents/GitHub/RADIANT_PCA/BRIM_Analytics/local_llm_extraction/Dictionary/CBTN_DataDictionary_2025-10-15.csv')

print(f"\nPatient ID: {patient_id}")
print(f"Birth Date: {birth_date}")
print(f"Staging Path: {staging_base}")

# Initialize pipeline
print("\n1. Initializing Integrated Pipeline...")
pipeline = IntegratedPipelineExtractor(
    staging_base_path=str(staging_base),
    binary_files_path=str(binary_files_path),
    data_dictionary_path=str(data_dictionary_path),
    ollama_model='gemma2:27b'
)
print("   ‚úì Pipeline initialized with real Ollama implementation")

# Run comprehensive extraction
print("\n2. Running comprehensive extraction (all 5 phases)...")
print("-"*80)

try:
    result = pipeline.extract_patient_comprehensive(
        patient_id=patient_id,
        birth_date=birth_date
    )

    print("\n‚úì Extraction completed successfully!")

except Exception as e:
    logger.error(f"Extraction failed: {e}", exc_info=True)
    result = {"error": str(e)}

# Analyze and display results
print("\n" + "="*80)
print("EXTRACTION RESULTS")
print("="*80)

if 'error' not in result:
    # Phase 1 Summary
    if 'structured_features' in result:
        features = result['structured_features']
        print("\nüìä PHASE 1 - Structured Data Harvesting:")
        print(f"   ‚Ä¢ Total features extracted: {len(features)}")

        # Key findings
        key_features = ['has_surgery', 'has_chemotherapy', 'has_radiation_therapy',
                       'initial_diagnosis_date', 'tumor_location', 'histology']
        for key in key_features:
            if key in features:
                value = features[key]
                if value and value != 'Not found':
                    print(f"   ‚Ä¢ {key}: {value}")

    # Phase 2 Summary
    if 'timeline' in result:
        timeline = result['timeline']
        print(f"\nüìÖ PHASE 2 - Clinical Timeline:")
        print(f"   ‚Ä¢ Total events: {len(timeline)}")
        if timeline:
            # Show first few events
            for event in timeline[:3]:
                print(f"   ‚Ä¢ {event.get('event_date')}: {event.get('event_type')}")

    # Events with extraction results
    if 'events' in result and result['events']:
        print(f"\nüî¨ PHASE 3-5 - Document Processing & Extraction:")

        for i, event in enumerate(result['events'][:2], 1):  # Show first 2 events
            print(f"\n   Event {i}: {event.get('event_type')} ({event.get('event_date')})")

            # Document stats
            if 'document_stats' in event:
                stats = event['document_stats']
                total_docs = stats.get('total_documents', 0)
                print(f"      Documents selected: {total_docs}")
                print(f"      Efficiency: {total_docs / 22127 * 100:.3f}% of available")

            # Extraction results
            if 'extracted_variables' in event:
                extracted = event['extracted_variables']
                successful_vars = []

                for var, res in extracted.items():
                    if isinstance(res, dict):
                        val = res.get('value')
                        if val and val not in ['Unable to extract', 'Not found', None]:
                            successful_vars.append((var, res))

                if successful_vars:
                    print(f"      Variables extracted: {len(successful_vars)}/{len(extracted)}")
                    print(f"      Key extractions:")
                    for var, res in successful_vars[:5]:  # Show up to 5
                        conf = res.get('confidence', 0)
                        print(f"        ‚Ä¢ {var}: {res['value']} (confidence: {conf:.2f})")
                else:
                    print(f"      Variables attempted: {len(extracted)}")
                    print(f"      Note: Ollama may need prompt optimization")

    # Overall summary
    print("\n" + "="*80)
    print("SUMMARY")
    print("="*80)

    total_events = len(result.get('events', []))
    total_vars_attempted = sum(len(e.get('extracted_variables', {})) for e in result.get('events', []))
    total_docs_processed = sum(e.get('document_stats', {}).get('total_documents', 0) for e in result.get('events', []))

    print(f"‚Ä¢ Patient: {patient_id}")
    print(f"‚Ä¢ Clinical events processed: {total_events}")
    print(f"‚Ä¢ Total documents selected: {total_docs_processed} (out of 22,127 available)")
    print(f"‚Ä¢ Document efficiency: {total_docs_processed / 22127 * 100:.3f}%")
    print(f"‚Ä¢ Variables extraction attempted: {total_vars_attempted}")
    print(f"‚Ä¢ Ollama LLM: ‚úì Connected and operational")

else:
    print(f"\n‚ùå Extraction failed: {result['error']}")

# Save complete results
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
output_file = f'final_extraction_results_{patient_id}_{timestamp}.json'

with open(output_file, 'w') as f:
    json.dump(result, f, indent=2, default=str)

print(f"\nüìÅ Complete results saved to: {output_file}")
print("\nYou can now review the full extraction results in the JSON file.")
print("The pipeline used REAL Ollama implementation with efficient document selection.")

print("\n" + "="*80)
print("EXTRACTION COMPLETE")
print("="*80)